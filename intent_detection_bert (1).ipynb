{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intent detection bert",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r5ZU1Rg7-MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-for-tf2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_sJpbuV8Cv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA399fR28Rpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eud6mCef8r9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gdown\n",
        "!pip install tensorflow_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onst3QMM8wXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade grpcio >> /dev/null\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9JF7ryE9PoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import bert\n",
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from matplotlib import rc\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBTaMITO9nsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown --id 1OlcvGWReJMuyYQuOZm149vHWwPtlboR6 --output train.csv\n",
        "!gdown --id 1Oi5cRlTybuIF2Fl5Bfsr-KkqrXrdt77w --output valid.csv\n",
        "!gdown --id 1ep9H6-HvhB4utJRLVcLzieWNUSG3P_uF --output test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDlmQYfo-He3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "valid = pd.read_csv(\"valid.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5nu6Oub-NRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.append(valid).reset_index(drop=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CPKro_d_Ayq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dmO7bEE_DFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chart = sns.countplot(train.intent, palette=HAPPY_COLORS_PALETTE)\n",
        "plt.title(\"Number of texts per intent\")\n",
        "chart.set_xticklabels(chart.get_xticklabels(), rotation=30, horizontalalignment='right');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJzhBGyn_VMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQWSkvclBw2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip uncased_L-12_H-768_A-12.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4apxJrqB011",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(\"model\", exist_ok=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5cCy_KiB3Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv uncased_L-12_H-768_A-12/ model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3mLODqLB5_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
        "\n",
        "bert_ckpt_dir = os.path.join(\"model/\", bert_model_name)\n",
        "bert_ckpt_file = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc0gHh7EDBYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7VkTjIaCHjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IntentDetectionData:\n",
        "  DATA_COLUMN='text'\n",
        "  LABEL_COLUMN='intent'\n",
        "\n",
        "  def __init__(self,train,test,tokenizer: FullTokenizer,classes,max_seq_len=192):\n",
        "    self.tokenizer=tokenizer\n",
        "    self.max_seq_len=0\n",
        "    self.classes=classes\n",
        "\n",
        "    ((self.train_x,self.train_y),(self.test_x,self.test_y)) = map(self._prepare,[train,test])\n",
        "    self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "    self.train_x,self.test_x = map(self._pad,[self.train_x,self.test_x])\n",
        "\n",
        "\n",
        "  def _prepare(self,df):\n",
        "    x ,y =[],[]\n",
        "    for _,row in tqdm(df.iterrows()):\n",
        "      text,label=row[IntentDetectionData.DATA_COLUMN], row[IntentDetectionData.LABEL_COLUMN]\n",
        "      tokens = self.tokenizer.tokenize(text)\n",
        "      tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "      self.max_seq_len=max(self.max_seq_len,len(token_ids))\n",
        "      x.append(token_ids)\n",
        "      y.append(self.classes.index(label))\n",
        "    return np.array(x),np.array(y)\n",
        "  \n",
        "  def _pad(self,ids):\n",
        "    x=[]\n",
        "    for input_ids in ids:\n",
        "      cut_point=min(len(input_ids),self.max_seq_len-2)\n",
        "      input_ids=input_ids[:cut_point]\n",
        "      input_ids = input_ids +[0]*(self.max_seq_len - len(input_ids))\n",
        "      x.append(input_ids)\n",
        "\n",
        "    return np.array(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwInNt0tH-mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir,'vocab.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8rC9kk7IYmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.tokenize(\"I can't wait to visit bulgaria again!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcoBGxNSIjK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(max_seq_len,bert_config_file,bert_ckpt_file):\n",
        "  with tf.io.gfile.GFile(bert_config_file,'r') as reader:\n",
        "    bc = StockBertConfig.from_json_string(reader.read())\n",
        "    bert_params=map_stock_config_to_params(bc)\n",
        "    bert_params.adapter_size = None\n",
        "    bert = BertModelLayer.from_params(bert_params, name = 'bert')\n",
        "\n",
        "  input_ids = keras.layers.Input(shape=(max_seq_len,),dtype='int32',name='input_ids')\n",
        "  bert_output=bert(input_ids)\n",
        "\n",
        "  print('bert shape',bert_output.shape)\n",
        "\n",
        "  cls_out = keras.layers.Lambda(lambda seq : seq[:,0,:])(bert_output)\n",
        "  cls_out= keras.layers.Dropout(0.5)(cls_out)\n",
        "  logits = keras.layers.Dense(units=768, activation='tanh')(cls_out)\n",
        "  logits = keras.layers.Dropout(0.5)(logits)\n",
        "  logits = keras.layers.Dense(units=len(classes), activation='softmax')(logits)\n",
        "  model=keras.Model(inputs=input_ids, outputs=logits)\n",
        "  model.build(input_shape=(None, max_seq_len))\n",
        "\n",
        "  load_stock_weights(bert, bert_ckpt_file)\n",
        "        \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMUASC8sKUfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = train.intent.unique().tolist()\n",
        "data =IntentDetectionData(train,test,tokenizer,classes,max_seq_len=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxUgGsfNKtLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=create_model(data.max_seq_len,bert_config_file,bert_ckpt_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9jUjyv8LXTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.train_x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v92T609NNhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.train_y.shape "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOYqsnd5Nxzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-70rh9EN7EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(1e-5),loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[keras.metrics.SparseCategoricalCrossentropy(name='acc')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3QdqJevOj0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "  x=data.train_x, \n",
        "  y=data.train_y,\n",
        "  validation_split=0.1,\n",
        "  batch_size=16,\n",
        "  shuffle=True,\n",
        "  epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hGQI7IrPMnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}